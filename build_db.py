"""
data/raw ã«ã‚ã‚‹ PDF ã‚’ç›´æ¥èª­ã¿è¾¼ã‚“ã§ãƒ™ã‚¯ãƒˆãƒ«DB ã‚’æ§‹ç¯‰
"""
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.ingestion.extract import extract_text_from_pdf
from src.ingestion.chunking import chunk_text
from src.embedding.store import store_embeddings

load_dotenv()

def build_vector_db():
    """data/raw ã® PDF ã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«DB ã‚’æ§‹ç¯‰"""
    
    raw_dir = "data/raw"
    storage_path = "storage/chroma"
    
    # data/raw å†…ã® PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pdf_files = list(Path(raw_dir).glob("*.pdf"))
    
    if not pdf_files:
        print(f"âŒ {raw_dir} ã« PDF ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    pdf_path = pdf_files[0]
    print(f"ğŸ“„ PDF ã‚’å‡¦ç†ä¸­: {pdf_path}")
    
    # 1. PDF ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    print("\n1. ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­...")
    pages = extract_text_from_pdf(str(pdf_path))
    print(f"   âœ“ {len(pages)} ãƒšãƒ¼ã‚¸ã‚’æŠ½å‡º")
    
    # 2. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    print("\n2. ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ä¸­...")
    chunks = chunk_text(pages, chunk_size=500)
    print(f"   âœ“ {len(chunks)} ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ")
    
    # 3. ãƒ™ã‚¯ãƒˆãƒ«DB ã«ä¿å­˜
    print("\n3. ãƒ™ã‚¯ãƒˆãƒ«DB ã«ä¿å­˜ä¸­...")
    print("   ï¼ˆã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™...ï¼‰")
    
    # ChromaDB ã«ç›´æ¥ä¿å­˜
    import chromadb
    from chromadb.utils import embedding_functions
    import google.generativeai as genai
    
    # ChromaDB ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
    client = chromadb.PersistentClient(path=storage_path)
    
    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆã¾ãŸã¯å–å¾—
    try:
        collection = client.get_collection(name="pdf_documents")
        print("   æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨")
    except:
        # Gemini åŸ‹ã‚è¾¼ã¿é–¢æ•°
        genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
        
        class GoogleGenerativeAiEmbeddingFunction(embedding_functions.EmbeddingFunction):
            def __call__(self, input: list[str]) -> list[list[float]]:
                embeddings = []
                for text in input:
                    result = genai.embed_content(
                        model="models/text-embedding-004",
                        content=text,
                        task_type="RETRIEVAL_DOCUMENT"
                    )
                    embeddings.append(result['embedding'])
                return embeddings
        
        gemini_ef = GoogleGenerativeAiEmbeddingFunction()
        collection = client.create_collection(
            name="pdf_documents",
            embedding_function=gemini_ef,
            metadata={"hnsw:space": "cosine"}
        )
        print("   æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ")
    
    # ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
    documents = [chunk["content"] for chunk in chunks]
    metadatas = [chunk["metadata"] for chunk in chunks]
    ids = [f"chunk_{i}" for i in range(len(chunks))]
    
    collection.add(
        documents=documents,
        metadatas=metadatas,
        ids=ids
    )
    
    print(f"\nâœ… ãƒ™ã‚¯ãƒˆãƒ«DB ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"   - ãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")
    print(f"   - ä¿å­˜å…ˆ: {storage_path}")
    return True

if __name__ == "__main__":
    print("=" * 80)
    print("ãƒ™ã‚¯ãƒˆãƒ«DB æ§‹ç¯‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 80)
    
    success = build_vector_db()
    
    if success:
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  python debug_search.py  # æ¤œç´¢å“è³ªã‚’ç¢ºèª")
    
    sys.exit(0 if success else 1)
